---
title: "Robust Trimmed k-means"
collection: publications
permalink: /publication/2021-01-01-RTKM
excerpt: "When dealing with real-world data many traditional clustering algorithms are compromised by lack of clear separation between groups, noisy observations, and/or outlying data points. Current methods that robustify k-means clustering are specialized for either single or multi-membership data, but do not perform competitively in both cases. We propose an extension of the k-means algorithm, which we call Robust Trimmed k-means (RTKM) that simultaneously identifies outliers and clusters points and can be applied to either single- or multi-membership data.<br/><img src='/images/ConvergenceProcess.pdf'><br/>Clustering process of relaxed k-means. The colors of the points represent the continuum of weights that assign points to clusters. In iteration 0, all weights and cluster centers are assigned randomly. In iteration 3, two distinct clusters begin to form. In iteration 5, cluster centers begin to stabilize and points on the boundary retain partial membership to both clusters. In iteration 20, relaxed k-means converges to two distinct clusters."
date: 2021-01-01
venue: 'Pattern Recognition Letters'
paperurl: 'http://OlgaD400.github.io/files/RTKM.pdf'
---
Clustering is a fundamental tool in unsupervised learning, used to group objects by distinguishing between similar and dissimilar features of a given data set. One of the most common clustering algorithms is k-means. Unfortunately, when dealing with real-world data many traditional clustering algorithms are compromised by lack of clear separation between groups, noisy observations, and/or outlying data points. Thus, robust statistical algorithms are required for successful data analytics. Current methods that robustify k-means clustering are specialized for either single or multi-membership data, but do not perform competitively in both cases. We propose an extension of the k-means algorithm, which we call Robust Trimmed k-means (RTKM) that simultaneously identifies outliers and clusters points and can be applied to either single- or multi-membership data. We test RTKM on various real-world datasets and show that RTKM performs competitively with other methods on single membership data with outliers and multi- membership data without outliers. We also show that RTKM leverages its relative advantages to outper- form other methods on multi-membership data containing outliers.

[Download paper here](http://OlgaD400.github.io/files/RTKM.pdf)
